---
title: Overview
description: "Fine-tuning Large Language Models (LLMs) is a specialized process within machine learning that adapts pre-trained language models to perform specific tasks or to better understand particular domains. Given the immense capabilities and versatility of LLMs like Llama3, fine-tuning allows these models to deliver more accurate, relevant, and context-aware outputs tailored to specific applications or industries."
---

Given the immense capabilities and versatility of LLMs like Llama3, fine-tuning allows these models to deliver more accurate, relevant, and context-aware outputs tailored to specific applications or industries.

Fine-tuning empowers you to optimize the models available through the Lumino API, offering:
- More accurate outputs compared to basic prompts
- The ability to train with larger datasets beyond a single prompt
- Reduced token usage by minimizing prompt length
- Faster response times due to optimized requests

Fine-tuning leverages a larger set of examples to train the model, leading to better performance across a variety of tasks. With a fine-tuned model, you can drastically reduce the need for extensive prompt examples, lowering costs and improving response times.

Here’s a high-level overview of the fine-tuning process:
1. Prepare and upload your training data
2. Train open source models available on our platform
3. Evaluate the results and iterate if necessary
4. Start using your fine-tuned model for optimized performance

### Models Supported on Lumino for Fine-Tuning
Llama 3.1 8B
Llama 3.1 70B

## When to Consider Fine-Tuning
Fine-tuning is a powerful tool for those who require models to handle highly specific tasks or operate within particular constraints. However, before jumping into fine-tuning, we suggest leveraging prompt engineering and modular prompt chaining techniques. Here’s why:

- Many tasks can be solved with smart prompt configurations, reducing the need for training new models.
- Iterating on prompts is faster than running full fine-tuning cycles, allowing for quicker feedback and adjustments.
- Prompt engineering work can complement fine-tuning, as well-structured prompts often enhance the quality of the fine-tuning process.

For developers seeking faster results, we offer a guide on optimizing prompts directly in the Lumino API environment.

### Common Use Cases for Fine-Tuning
Here are some scenarios where fine-tuning can significantly enhance model performance:
- Task-specific adaptation: Fine-tuning general-purpose models like Llama or BERT for specific tasks such as question answering, text classification, or summarization.
- Domain specialization: Adapting models to perform well in specific industries or fields, like legal, medical, or scientific domains.
- Language localization: Improving performance on languages or dialects that weren't well-represented in the original training data.
- Company-specific knowledge integration: Incorporating proprietary information or domain expertise into the model.
- Low-resource applications: Adapting models for languages or domains with limited available data.
- Improved few-shot learning: Enhancing a model's ability to perform well on new tasks with minimal examples.
- Multimodal applications: Fine-tuning models to work with combinations of text, images, or other data types.
- Customized outputs: Set specific tones, formats, or styles that align with your brand or project needs.
- Consistency in complex tasks: Achieve a higher level of reliability when managing tasks with intricate or multi-step processes.
- Specialized behaviors: Teach the model to handle rare edge cases or new tasks that can’t easily be addressed with a generic prompt.

Additionally, fine-tuning can help reduce operational costs by optimizing smaller models for tasks that would otherwise require larger, more expensive ones. For example, by fine-tuning llama3.1_7B on task-specific datasets, you can achieve high-quality results at a fraction of the computational cost.

<b>Next Steps in Fine-Tuning</b>
In the sections that follow, we’ll guide you through how to prepare your data, initiate the fine-tuning process, and evaluate model performance to maximize the benefits of customization.

## Data Preparation

Effective fine-tuning begins with high-quality data preparation. Follow these steps to prepare your dataset:
1. Collect Relevant Data:
  - Gather data that is pertinent to your specific task or domain.
  - Ensure data diversity to cover various aspects of the target application.
2. Clean and Preprocess Data:
  - Remove any irrelevant or noisy data.
  - Standardize to JSON format.
  - Handle missing values and correct inconsistencies.
3. Annotate Data (If Necessary):
  - Label data appropriately for supervised learning tasks.
  - Use consistent labeling standards to maintain data quality.
4. Split Data:
  - Divide your dataset into training, validation, and testing subsets to evaluate model performance effectively.





